{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-8KcKaB6lGVGmvpfVwhJCT3lBHPVMG at 0x1175c6f90> JSON: {\n",
       "  \"id\": \"chatcmpl-8KcKaB6lGVGmvpfVwhJCT3lBHPVMG\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"created\": 1699924596,\n",
       "  \"model\": \"gpt-35-turbo-16k\",\n",
       "  \"prompt_filter_results\": [\n",
       "    {\n",
       "      \"prompt_index\": 0,\n",
       "      \"content_filter_results\": {\n",
       "        \"hate\": {\n",
       "          \"filtered\": false,\n",
       "          \"severity\": \"safe\"\n",
       "        },\n",
       "        \"self_harm\": {\n",
       "          \"filtered\": false,\n",
       "          \"severity\": \"safe\"\n",
       "        },\n",
       "        \"sexual\": {\n",
       "          \"filtered\": false,\n",
       "          \"severity\": \"safe\"\n",
       "        },\n",
       "        \"violence\": {\n",
       "          \"filtered\": false,\n",
       "          \"severity\": \"safe\"\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  ],\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"index\": 0,\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"message\": {\n",
       "        \"role\": \"assistant\",\n",
       "        \"content\": \"How can I assist you today?\"\n",
       "      },\n",
       "      \"content_filter_results\": {\n",
       "        \"hate\": {\n",
       "          \"filtered\": false,\n",
       "          \"severity\": \"safe\"\n",
       "        },\n",
       "        \"self_harm\": {\n",
       "          \"filtered\": false,\n",
       "          \"severity\": \"safe\"\n",
       "        },\n",
       "        \"sexual\": {\n",
       "          \"filtered\": false,\n",
       "          \"severity\": \"safe\"\n",
       "        },\n",
       "        \"violence\": {\n",
       "          \"filtered\": false,\n",
       "          \"severity\": \"safe\"\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 18,\n",
       "    \"completion_tokens\": 7,\n",
       "    \"total_tokens\": 25\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Note: The openai-python library support for Azure OpenAI is in preview.\n",
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 環境変数の読み込み\n",
    "load_dotenv()\n",
    "openai.api_type = os.environ[\"API_TYPE\"]\n",
    "openai.api_base = os.environ[\"API_BASE\"]\n",
    "openai.api_version = os.environ[\"API_VERSION\"]\n",
    "openai.api_key = os.environ[\"API_KEY\"]\n",
    "\n",
    "engine = os.environ[\"API_ENGINE\"]\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "  engine=engine\n",
    "  messages = [{\"role\":\"system\",\"content\":\"You are an AI assistant that helps people find information.\"}],\n",
    "  temperature=0.7,\n",
    "  max_tokens=800,\n",
    "  top_p=0.95,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0,\n",
    "  stop=None)\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "# 環境変数の読み込み\n",
    "load_dotenv()\n",
    "openai.api_type = os.environ[\"API_TYPE\"]\n",
    "openai.api_base = os.environ[\"API_BASE\"]\n",
    "openai.api_version = os.environ[\"API_VERSION\"]\n",
    "openai.api_key = os.environ[\"API_KEY\"]\n",
    "\n",
    "engine = os.environ[\"API_ENGINE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-8KcKbrB5tsFw5kVyhYryag5eupabF at 0x1175c7350> JSON: {\n",
       "  \"id\": \"chatcmpl-8KcKbrB5tsFw5kVyhYryag5eupabF\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"created\": 1699924597,\n",
       "  \"model\": \"gpt-35-turbo-16k\",\n",
       "  \"prompt_filter_results\": [\n",
       "    {\n",
       "      \"prompt_index\": 0,\n",
       "      \"content_filter_results\": {\n",
       "        \"hate\": {\n",
       "          \"filtered\": false,\n",
       "          \"severity\": \"safe\"\n",
       "        },\n",
       "        \"self_harm\": {\n",
       "          \"filtered\": false,\n",
       "          \"severity\": \"safe\"\n",
       "        },\n",
       "        \"sexual\": {\n",
       "          \"filtered\": false,\n",
       "          \"severity\": \"safe\"\n",
       "        },\n",
       "        \"violence\": {\n",
       "          \"filtered\": false,\n",
       "          \"severity\": \"safe\"\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  ],\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"index\": 0,\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"message\": {\n",
       "        \"role\": \"assistant\",\n",
       "        \"content\": \"\\u4ee5\\u4e0b\\u306e\\u3088\\u3046\\u306a\\u30dd\\u30a4\\u30f3\\u30c8\\u304c\\u8a00\\u8a9e\\u30e2\\u30c7\\u30eb\\u3092\\u4f7f\\u3046\\u4e0a\\u3067\\u91cd\\u8981\\u3067\\u3059\\u3002\\n\\n1. \\u8a13\\u7df4\\u30c7\\u30fc\\u30bf\\u306e\\u8cea\\u3068\\u91cf: \\u8a00\\u8a9e\\u30e2\\u30c7\\u30eb\\u306f\\u5927\\u91cf\\u306e\\u9ad8\\u54c1\\u8cea\\u306a\\u8a13\\u7df4\\u30c7\\u30fc\\u30bf\\u306b\\u4f9d\\u5b58\\u3057\\u3066\\u3044\\u307e\\u3059\\u3002\\u8a13\\u7df4\\u30c7\\u30fc\\u30bf\\u306f\\u3001\\u6587\\u6cd5\\u7684\\u306b\\u6b63\\u78ba\\u3067\\u591a\\u69d8\\u306a\\u6587\\u7ae0\\u3092\\u542b\\u307f\\u3001\\u30e2\\u30c7\\u30eb\\u306b\\u9069\\u5207\\u306a\\u8a00\\u8a9e\\u306e\\u7406\\u89e3\\u3092\\u63d0\\u4f9b\\u3059\\u308b\\u5fc5\\u8981\\u304c\\u3042\\u308a\\u307e\\u3059\\u3002\\n\\n2. \\u30e2\\u30c7\\u30eb\\u306e\\u9078\\u629e: \\u8a00\\u8a9e\\u30e2\\u30c7\\u30eb\\u306e\\u7a2e\\u985e\\u306b\\u306f\\u3001\\u53cc\\u65b9\\u5411\\u306eRNN\\u3084\\u30c8\\u30e9\\u30f3\\u30b9\\u30d5\\u30a9\\u30fc\\u30de\\u30fc\\u3068\\u547c\\u3070\\u308c\\u308b\\u3088\\u3046\\u306a\\u6ce8\\u610f\\u6a5f\\u69cb\\u3092\\u4f7f\\u7528\\u3057\\u305f\\u30e2\\u30c7\\u30eb\\u304c\\u3042\\u308a\\u307e\\u3059\\u3002\\u30bf\\u30b9\\u30af\\u306b\\u3088\\u3063\\u3066\\u6700\\u9069\\u306a\\u30e2\\u30c7\\u30eb\\u3092\\u9078\\u629e\\u3059\\u308b\\u5fc5\\u8981\\u304c\\u3042\\u308a\\u307e\\u3059\\u3002\\n\\n3. \\u30d1\\u30e9\\u30e1\\u30fc\\u30bf\\u8abf\\u6574: \\u30e2\\u30c7\\u30eb\\u306e\\u30d1\\u30e9\\u30e1\\u30fc\\u30bf\\u3092\\u9069\\u5207\\u306b\\u8abf\\u6574\\u3059\\u308b\\u3053\\u3068\\u3082\\u91cd\\u8981\\u3067\\u3059\\u3002\\u8a13\\u7df4\\u30c7\\u30fc\\u30bf\\u306b\\u9069\\u5408\\u3057\\u3059\\u304e\\u305f\\u30e2\\u30c7\\u30eb\\uff08\\u904e\\u5b66\\u7fd2\\uff09\\u3084\\u3001\\u8a13\\u7df4\\u30c7\\u30fc\\u30bf\\u306b\\u4e0d\\u9069\\u5408\\u306a\\u30e2\\u30c7\\u30eb\\uff08\\u672a\\u5b66\\u7fd2\\uff09\\u306f\\u3046\\u307e\\u304f\\u52d5\\u4f5c\\u3057\\u307e\\u305b\\u3093\\u3002\\u9069\\u5207\\u306a\\u30cf\\u30a4\\u30d1\\u30fc\\u30d1\\u30e9\\u30e1\\u30fc\\u30bf\\u306e\\u9078\\u629e\\u3068\\u30e2\\u30c7\\u30eb\\u306e\\u6b63\\u5247\\u5316\\u304c\\u5fc5\\u8981\\u3067\\u3059\\u3002\\n\\n4. \\u30d5\\u30a1\\u30a4\\u30f3\\u30c1\\u30e5\\u30fc\\u30cb\\u30f3\\u30b0: \\u4e8b\\u524d\\u5b66\\u7fd2\\u6e08\\u307f\\u306e\\u8a00\\u8a9e\\u30e2\\u30c7\\u30eb\\u3092\\u4f7f\\u7528\\u3059\\u308b\\u5834\\u5408\\u3001\\u8ffd\\u52a0\\u306e\\u30bf\\u30b9\\u30af\\u306b\\u5bfe\\u3057\\u3066\\u30e2\\u30c7\\u30eb\\u3092\\u5fae\\u8abf\\u6574\\u3059\\u308b\\u3053\\u3068\\u304c\\u4e00\\u822c\\u7684\\u3067\\u3059\\u3002\\u3053\\u308c\\u306b\\u3088\\u308a\\u3001\\u7279\\u5b9a\\u306e\\u30bf\\u30b9\\u30af\\u306b\\u30e2\\u30c7\\u30eb\\u3092\\u9069\\u5fdc\\u3055\\u305b\\u308b\\u3053\\u3068\\u304c\\u3067\\u304d\\u307e\\u3059\\u3002\\n\\n5. \\u51fa\\u529b\\u306e\\u8a55\\u4fa1: \\u8a00\\u8a9e\\u30e2\\u30c7\\u30eb\\u304b\\u3089\\u751f\\u6210\\u3055\\u308c\\u305f\\u51fa\\u529b\\u306e\\u54c1\\u8cea\\u8a55\\u4fa1\\u306f\\u91cd\\u8981\\u3067\\u3059\\u3002\\u81ea\\u52d5\\u8a55\\u4fa1\\u6307\\u6a19\\uff08\\u4f8b\\uff1aBLEU\\u3001ROUGE\\uff09\\u3001\\u4eba\\u624b\\u306b\\u3088\\u308b\\u8a55\\u4fa1\\u3001\\u53d7\\u5bb9\\u6027\\u30c6\\u30b9\\u30c8\\u306a\\u3069\\u3001\\u9069\\u5207\\u306a\\u8a55\\u4fa1\\u65b9\\u6cd5\\u3092\\u9078\\u629e\\u3059\\u308b\\u5fc5\\u8981\\u304c\\u3042\\u308a\\u307e\\u3059\\u3002\\n\\n6. \\u8aa4\\u308a\\u3078\\u306e\\u5bfe\\u51e6: \\u8a00\\u8a9e\\u30e2\\u30c7\\u30eb\\u306f\\u8aa4\\u308a\\u3092 com:\\u30b3\\u30df\\u30c3\\u30c8\\u3059\\u308b\\u3053\\u3068\\u304c\\u3042\\u308a\\u307e\\u3059\\u3002\\u8aa4\\u308a\\u3092\\u4fee\\u6b63\\u3059\\u308b\\u305f\\u3081\\u306b\\u306f\\u3001\\u51fa\\u529b\\u306e\\u54c1\\u8cea\\u3092\\u5411\\u4e0a\\u3055\\u305b\\u308b\\u305f\\u3081\\u306e\\u5f8c\\u51e6\\u7406\\u30b9\\u30c6\\u30c3\\u30d7\\u3084\\u3001\\u30a8\\u30e9\\u30fc\\u30c7\\u30a3\\u30c6\\u30af\\u30b7\\u30e7\\u30f3\\u3068\\u3044\\u3063\\u305f\\u624b\\u6cd5\\u304c\\u5fc5\\u8981\\u306b\\u306a\\u308b\\u5834\\u5408\\u304c\\u3042\\u308a\\u307e\\u3059\\u3002\\n\\n7. \\u30c7\\u30fc\\u30bf\\u306e\\u30d0\\u30a4\\u30a2\\u30b9: \\u8a13\\u7df4\\u30c7\\u30fc\\u30bf\\u306b\\u30d0\\u30a4\\u30a2\\u30b9\\u304c\\u3042\\u308b\\u5834\\u5408\\u3001\\u8a00\\u8a9e\\u30e2\\u30c7\\u30eb\\u3082\\u305d\\u306e\\u30d0\\u30a4\\u30a2\\u30b9\\u3092\\u53cd\\u6620\\u3059\\u308b\\u53ef\\u80fd\\u6027\\u304c\\u3042\\u308a\\u307e\\u3059\\u3002\\u30e2\\u30c7\\u30eb\\u306e\\u5b66\\u7fd2\\u30c7\\u30fc\\u30bf\\u3092\\u9069\\u5207\\u306b\\u30d0\\u30e9\\u30f3\\u30b9\\u3055\\u305b\\u308b\\u305f\\u3081\\u3001\\u30c7\\u30fc\\u30bf\\u30bb\\u30c3\\u30c8\\u306e\\u30ab\\u30d0\\u30ec\\u30c3\\u30b8\\u3068\\u591a\\u69d8\\u6027\\u3092\\u78ba\\u8a8d\\u3059\\u308b\\u3053\\u3068\\u3082\\u91cd\\u8981\\u3067\\u3059\\u3002\\n\\n8. \\u30ea\\u30a2\\u30eb\\u30bf\\u30a4\\u30e0\\u6027\\u3084\\u30ea\\u30bd\\u30fc\\u30b9\\u5236\\u7d04: \\u8a00\\u8a9e\\u30e2\\u30c7\\u30eb\\u3092\\u30ea\\u30a2\\u30eb\\u30bf\\u30a4\\u30e0\\u3067\\u4f7f\\u7528\\u3059\\u308b\\u5834\\u5408\\u3001\\u51e6\\u7406\\u901f\\u5ea6\\u3084\\u30ea\\u30bd\\u30fc\\u30b9\\uff08\\u30e1\\u30e2\\u30ea\\u3001CPU\\u3001GPU\\uff09\\u306e\\u5236\\u7d04\\u306b\\u5bfe\\u3057\\u3066\\u6700\\u9069\\u5316\\u3059\\u308b\\u5fc5\\u8981\\u304c\\u3042\\u308a\\u307e\\u3059\\u3002\\n\\n\\u3053\\u308c\\u3089\\u306e\\u30dd\\u30a4\\u30f3\\u30c8\\u3092\\u8003\\u616e\\u3057\\u306a\\u304c\\u3089\\u3001\\u9069\\u5207\\u306a\\u8a00\\u8a9e\\u30e2\\u30c7\\u30eb\\u3092\\u8a13\\u7df4\\u304a\\u3088\\u3073\\u4f7f\\u7528\\u3059\\u308b\\u3088\\u3046\\u306b\\u3059\\u308b\\u3053\\u3068\\u304c\\u91cd\\u8981\\u3067\\u3059\\u3002\"\n",
       "      },\n",
       "      \"content_filter_results\": {\n",
       "        \"hate\": {\n",
       "          \"filtered\": false,\n",
       "          \"severity\": \"safe\"\n",
       "        },\n",
       "        \"self_harm\": {\n",
       "          \"filtered\": false,\n",
       "          \"severity\": \"safe\"\n",
       "        },\n",
       "        \"sexual\": {\n",
       "          \"filtered\": false,\n",
       "          \"severity\": \"safe\"\n",
       "        },\n",
       "        \"violence\": {\n",
       "          \"filtered\": false,\n",
       "          \"severity\": \"safe\"\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 24,\n",
       "    \"completion_tokens\": 910,\n",
       "    \"total_tokens\": 934\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# メッセージの設定\n",
    "message = \"言語モデルを使う上でのポイントは\"\n",
    "\n",
    "# APIリクエスト\n",
    "# https://platform.openai.com/docs/api-reference/chat/create\n",
    "response = openai.ChatCompletion.create(\n",
    "    engine=model_name,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": message},\n",
    "    ]\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "以下のようなポイントが言語モデルを使う上で重要です。\n",
      "\n",
      "1. 訓練データの質と量: 言語モデルは大量の高品質な訓練データに依存しています。訓練データは、文法的に正確で多様な文章を含み、モデルに適切な言語の理解を提供する必要があります。\n",
      "\n",
      "2. モデルの選択: 言語モデルの種類には、双方向のRNNやトランスフォーマーと呼ばれるような注意機構を使用したモデルがあります。タスクによって最適なモデルを選択する必要があります。\n",
      "\n",
      "3. パラメータ調整: モデルのパラメータを適切に調整することも重要です。訓練データに適合しすぎたモデル（過学習）や、訓練データに不適合なモデル（未学習）はうまく動作しません。適切なハイパーパラメータの選択とモデルの正則化が必要です。\n",
      "\n",
      "4. ファインチューニング: 事前学習済みの言語モデルを使用する場合、追加のタスクに対してモデルを微調整することが一般的です。これにより、特定のタスクにモデルを適応させることができます。\n",
      "\n",
      "5. 出力の評価: 言語モデルから生成された出力の品質評価は重要です。自動評価指標（例：BLEU、ROUGE）、人手による評価、受容性テストなど、適切な評価方法を選択する必要があります。\n",
      "\n",
      "6. 誤りへの対処: 言語モデルは誤りを com:コミットすることがあります。誤りを修正するためには、出力の品質を向上させるための後処理ステップや、エラーディテクションといった手法が必要になる場合があります。\n",
      "\n",
      "7. データのバイアス: 訓練データにバイアスがある場合、言語モデルもそのバイアスを反映する可能性があります。モデルの学習データを適切にバランスさせるため、データセットのカバレッジと多様性を確認することも重要です。\n",
      "\n",
      "8. リアルタイム性やリソース制約: 言語モデルをリアルタイムで使用する場合、処理速度やリソース（メモリ、CPU、GPU）の制約に対して最適化する必要があります。\n",
      "\n",
      "これらのポイントを考慮しながら、適切な言語モデルを訓練および使用するようにすることが重要です。\n"
     ]
    }
   ],
   "source": [
    "# 言語モデルからの回答を表示\n",
    "print(response.choices[0][\"message\"][\"content\"].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "昼食のおすすめは、たこ焼きやお好み焼きですね！大阪ならではの美味しい料理ですよ！あとは、もちろんお寿司やうどんもおすすめです！どれも美味しいので、ぜひ試してみてくださいや〜！\n",
      "--------------------\n",
      "おおきに！昼食のおすすめ、言うとったら、たこ焼きやお好み焼きがおすすめやねん。大阪はたこ焼きやお好み焼きの本場やから、味はばっちりやで。あとは、焼きそばやおいしいラーメンも人気やね\n",
      "--------------------\n",
      "おおきに！昼飯のおすすめは、たこ焼きやお好み焼き、串カツや焼き鳥など、大阪らしい「おでんげえ（美味しい）メニュー」がいっぱいあるんやで！どれもおいしいねんけど、たこ焼きは外\n"
     ]
    }
   ],
   "source": [
    "# 役割を設定\n",
    "role = \"あなたは関西人です。大阪弁を使います。\"\n",
    "# メッセージの設定\n",
    "message = \"おすすめの昼食はなんですか？\"\n",
    "\n",
    "# APIリクエスト\n",
    "response = openai.ChatCompletion.create(\n",
    "    engine = model_name,\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": role},\n",
    "        {\"role\": \"user\", \"content\": message},\n",
    "    ],\n",
    "    n = 3,\n",
    "    max_tokens = 100,\n",
    "    # 出力の多様性を制御するパラメーター\n",
    "    # temperature = 0.0\n",
    "    # top_p = 0.4\n",
    ")\n",
    "\n",
    "# 結果を表示\n",
    "for choice in response.choices:\n",
    "    print(\"-\" * 20)\n",
    "    print(choice[\"message\"][\"content\"].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "以下のポイントに留意する必要があります：\n",
      "\n",
      "1. データセットの選択: 使用するデータセットは、タスクと言語モデルの目標に合わせて適切に選ばれるべきです。多様なジャンルや文体が含まれており、十分な量の\n",
      "--------------------\n",
      "以下のようなポイントが重要です。\n",
      "\n",
      "1. データの品質と量: 良質なデータセットを用意し、モデル学習に使用するトレーニングデータの量を増やすことが重要です。大規模なデータセットは言語モデルのパフォーマン\n",
      "--------------------\n",
      "以下のようなポイントが挙げられます。\n",
      "\n",
      "1. データの準備: 言語モデルを訓練するためには、大量のトレーニングデータが必要です。これにはテキストコーパスやウェブから取得した文章などを使用します。データのクオリテ\n"
     ]
    }
   ],
   "source": [
    "# メッセージの設定\n",
    "message = \"言語モデルを使う上でのポイントは\"\n",
    "\n",
    "# APIリクエスト\n",
    "response = openai.ChatCompletion.create(\n",
    "    engine = model_name,\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": message},\n",
    "    ],\n",
    "    n = 3,\n",
    "    max_tokens = 100,\n",
    "    # 同じ単語の使用頻度を制御するパラメーター\n",
    "    presence_penalty = 2.0 # -2.0\n",
    ")\n",
    "\n",
    "# 結果を表示\n",
    "for choice in response.choices:\n",
    "    print(\"-\" * 20)\n",
    "    print(choice[\"message\"][\"content\"].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "from tiktoken.core import Encoding\n",
    "\n",
    "model_name = \"gpt-3.5-turbo\"\n",
    "# OpenAI APIの特定のモデルに対応するトークナイザーを取得\n",
    "encoding: Encoding = tiktoken.encoding_for_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens_count=9\n",
      "tokens=[90115, 6447, 78244, 45918, 252, 2845, 95, 68408, 33710]\n"
     ]
    }
   ],
   "source": [
    "# テキストをトークンIDのリストに変換\n",
    "tokens = encoding.encode(\"こんにちは！言語モデル\")\n",
    "tokens_count = len(tokens)\n",
    "print(f\"{tokens_count=}\")\n",
    "print(f\"{tokens=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "こんにちは,！,言,b'\\xe8\\xaa',b'\\x9e',b'\\xe3\\x83',b'\\xa2',デ,ル,"
     ]
    }
   ],
   "source": [
    "# トークンの単位を確認\n",
    "for token in tokens:\n",
    "    # トークンをバイト列にデコード\n",
    "    bytes = encoding.decode_tokens_bytes([token])[0]\n",
    "    # 文字に変換できるものは変換して表示\n",
    "    try:\n",
    "        print(bytes.decode(\"utf-8\"), end=\",\")\n",
    "    except UnicodeDecodeError:\n",
    "        print(bytes, end=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "おはよう！元気？\n",
      "--------------------\n",
      "おはよう！こんにちは！\n",
      "--------------------\n",
      "おはよう！こんにちは！元気？\n",
      "A: 元気！最近、どうしてる？\n",
      "B: ちょっと忙しいけど、頑張ってるよ！お前は？\n",
      "A: 普通！最近は仕事もプライベートも順調だよ！\n",
      "B: それは良かった！何か楽しいことでもあった？\n",
      "A: 先週は友達と旅行に行ってきた！とても楽しかった！\n",
      "B: いいな！どこに行ったの？\n",
      "A: 神奈川県の湘南！海を満喫したよ！波乗りもできた！\n",
      "B: 素晴らしい！私も海に行きたい！夏が待ち遠しい！\n",
      "A: そうだ！一緒に海へ行こう！\n",
      "B: もちろん！楽しみにしてる！\n"
     ]
    }
   ],
   "source": [
    "# logit_bias\n",
    "\n",
    "message = \"\"\"\n",
    "AさんとBさんで会話してください。\n",
    "A: おはよう！\n",
    "B:\n",
    "\"\"\"\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    engine = engine,\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": message},\n",
    "    ],\n",
    "    max_tokens = 300,\n",
    "    n = 3,\n",
    "    # \"こんにちは\",\"！\" のトークンIDが選ばれやすくなるよう指定\n",
    "    logit_bias = {90115:8, 6447:8}\n",
    ")\n",
    "\n",
    "# 結果を表示\n",
    "for choice in response.choices:\n",
    "    print(\"-\"*20)\n",
    "    print(choice[\"message\"][\"content\"].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "おすすめの昼食は、もつ鍋や博多\n",
      "--------------------\n",
      "おすすめの昼食は、「博多\n",
      "--------------------\n",
      "おすすめの昼食は「とんこつ\n"
     ]
    }
   ],
   "source": [
    "# stop\n",
    "\n",
    "role = \"あなたは博多出身です。博多弁を使います。\"\n",
    "# メッセージ\n",
    "message = \"おすすめの昼食はなんですか？\"\n",
    "stop_word = \"ラーメン\"\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    engine=engine,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": role},\n",
    "        {\"role\": \"user\", \"content\": message},\n",
    "    ],\n",
    "    n=3,\n",
    "    max_tokens=300,\n",
    "    stop=stop_word,\n",
    ")\n",
    "\n",
    "# 結果を表示\n",
    "for choice in response.choices:\n",
    "    print(\"-\" * 20)  # --------------------　と出力される\n",
    "    print(choice[\"message\"][\"content\"].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidRequestError",
     "evalue": "Unrecognized request argument supplied: steam",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/juri_ohto/Documents/ML_Project/ChatGPT_Chatbot/Sample/chat01_sample.ipynb Cell 12\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/juri_ohto/Documents/ML_Project/ChatGPT_Chatbot/Sample/chat01_sample.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# stream\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/juri_ohto/Documents/ML_Project/ChatGPT_Chatbot/Sample/chat01_sample.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m message \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m言語モデルを使う上でのポイントは\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/juri_ohto/Documents/ML_Project/ChatGPT_Chatbot/Sample/chat01_sample.ipynb#X14sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m response \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mChatCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/juri_ohto/Documents/ML_Project/ChatGPT_Chatbot/Sample/chat01_sample.ipynb#X14sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     engine\u001b[39m=\u001b[39;49mmodel_name,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/juri_ohto/Documents/ML_Project/ChatGPT_Chatbot/Sample/chat01_sample.ipynb#X14sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     messages\u001b[39m=\u001b[39;49m[\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/juri_ohto/Documents/ML_Project/ChatGPT_Chatbot/Sample/chat01_sample.ipynb#X14sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         {\u001b[39m\"\u001b[39;49m\u001b[39mrole\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39muser\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m\"\u001b[39;49m: message},\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/juri_ohto/Documents/ML_Project/ChatGPT_Chatbot/Sample/chat01_sample.ipynb#X14sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     ],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/juri_ohto/Documents/ML_Project/ChatGPT_Chatbot/Sample/chat01_sample.ipynb#X14sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     steam\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/juri_ohto/Documents/ML_Project/ChatGPT_Chatbot/Sample/chat01_sample.ipynb#X14sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/juri_ohto/Documents/ML_Project/ChatGPT_Chatbot/Sample/chat01_sample.ipynb#X14sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m response:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/juri_ohto/Documents/ML_Project/ChatGPT_Chatbot/Sample/chat01_sample.ipynb#X14sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39mnext\u001b[39m \u001b[39m=\u001b[39m chunk[\u001b[39m\"\u001b[39m\u001b[39mchoices\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mdelta\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/ML_Project/ChatGPT_Chatbot/Sample/.venv/lib/python3.11/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/Documents/ML_Project/ChatGPT_Chatbot/Sample/.venv/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    155\u001b[0m         url,\n\u001b[1;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/Documents/ML_Project/ChatGPT_Chatbot/Sample/.venv/lib/python3.11/site-packages/openai/api_requestor.py:298\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    278\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    279\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    287\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m    288\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    289\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    290\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    296\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    297\u001b[0m     )\n\u001b[0;32m--> 298\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[1;32m    299\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/Documents/ML_Project/ChatGPT_Chatbot/Sample/.venv/lib/python3.11/site-packages/openai/api_requestor.py:700\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    692\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    693\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    694\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    695\u001b[0m         )\n\u001b[1;32m    696\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[1;32m    697\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    698\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 700\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    701\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    702\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[1;32m    703\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    704\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    705\u001b[0m         ),\n\u001b[1;32m    706\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    707\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/ML_Project/ChatGPT_Chatbot/Sample/.venv/lib/python3.11/site-packages/openai/api_requestor.py:763\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    761\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[1;32m    762\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 763\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[1;32m    764\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[1;32m    765\u001b[0m     )\n\u001b[1;32m    766\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mInvalidRequestError\u001b[0m: Unrecognized request argument supplied: steam"
     ]
    }
   ],
   "source": [
    "# stream\n",
    "\n",
    "message = \"言語モデルを使う上でのポイントは\"\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    engine=model_name, # 利用しているengineの問題でエラーなのかもしれない。https://community.openai.com/t/insertion-unrecognized-request-argument-supplied-suffix/19035\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": message},\n",
    "    ],\n",
    "    steam=True,\n",
    ")\n",
    "\n",
    "for chunk in response:\n",
    "    next = chunk[\"choices\"][0][\"delta\"].get(\"content\", \"\")\n",
    "    print(next, end=\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
